/**
 * @file tpl_machine_arm_generic_asm.S
 *
 * @section descr File description
 *
 * Low level part of generic ARM platform
 *
 * This includes system call mechanism and IRQ (category 2 interrupts)
 * handling (at low level).
 *
 * @section copyright Copyright
 *
 * Trampoline OS
 *
 * Trampoline is copyright (c) IRCCyN 2005+
 * Copyright ESEO for function and data structures documentation and ARM port
 * Trampoline is protected by the French intellectual property law.
 *
 * This software is distributed under the Lesser GNU Public Licence
 *
 * @section infos File informations
 *
 * $Date$
 * $Rev$
 * $Author$
 * $URL$
 */

#include "tpl_asm_macros.h" /* this file should be defined in end platform (eg SIMTEC) */

#include "../tpl_asm_definitions.h"

.bss
.align 2

nested_kernel_entrance_counter:
	.word 0

/* This macro is called whenever entering into kernel mode. It can
 * be either from system call or from an IRQ.
 *
 * The stack generated by this macro looks like this for
 * a system call :
 *
 *         |---------------------------|
 *         | task's return address     |
 * SP+18-> |---------------------------|
 *         | r9                        |
 * SP+14-> |---------------------------|
 *         | r3                        |
 * SP+10-> |---------------------------|
 *         | r2                        |
 * SP+C -> |---------------------------|
 *         | r1                        |
 * SP+8 -> |---------------------------|
 *         | r0                        |
 * SP+4 -> |---------------------------|
 *         | spsr #0                   |
 * SP   -> |---------------------------|
 *
 * The SPSR is pushed to make possible to nest system calls
 *
 * It is quite similar in other exception mode but as they
 * cannot be nested (in the same mode) and as they are not
 * synchronous with application code, the stack looks like
 * this :
 *
 *         |---------------------------|
 *         | task's return address     |
 * SP+18-> |---------------------------|
 *         | ip (r12)                  |
 * SP+14-> |---------------------------|
 *         | r9                        |
 * SP+10-> |---------------------------|
 *         | r3                        |
 * SP+C -> |---------------------------|
 *         | r2                        |
 * SP+8 -> |---------------------------|
 *         | r1                        |
 * SP+4 -> |---------------------------|
 *         | r0                        |
 * SP   -> |---------------------------|
 *
 */
.macro kernel_enter mode
kernel_enter_\mode:
	/* first we disable all IRQ
	 * to prevent any preemption from here
	 * to the related context switch
	 */
	msr cpsr_c, #(CPSR_IRQ_LOCKED | \mode)

	/* fix lr only in IRQ mode
	 */
.if (\mode == CPSR_IRQ_MODE)
	sub lr, lr, #4
.endif

	/* Save caller saved registers (EABI convention).
	 *
   * r9 is saved to be compatible with a widest range
   * of ARM ABIs.
   *
   * r12 is not saved in system calls because a system
   * call cannot occur when IP (r12) is used to set up the
   * stack frame.
	 */
.if (\mode == CPSR_SVC_MODE)
	stmfd sp!, {r0-r3,r9,lr}
.else
  stmfd sp!, {r0-r3,r9,ip,lr}
.endif

  /* System calls should be reentrant, so we have to
   * save the saved PSR on the stack. Be warned : SPSR is
   * not restored in kernel_exit macro but either in keep_context
   * or in context_switch macro */
.if (\mode == CPSR_SVC_MODE)
  mrs r1, spsr
  stmfd sp!, {r1}
.endif

  /* manage reentrance of kernel */
	ldr r1, =nested_kernel_entrance_counter
	ldr r2, [r1]
	add r2, r2, #1
	str r2, [r1]

	/* Save the current running task's
	 * identifier so we can know 
	 * from which task a context switch should be done.
   *
   * If we are in a nested entrance, we should
   * not set old_running_id again.
	 */
  cmp r2, #1
  bhi skip_set_old_running_\mode
	ldr r1, =old_running_id
	ldr r2, =tpl_running_id
	LDR_PROC_ID r0, [r2]
	STR_PROC_ID r0, [r1]

skip_set_old_running_\mode:

.endm

/* this macro is called whenever the kernel mode is to be exited */
.macro kernel_exit_no_switch mode
kernel_exit_\mode:
  /* manage reentrance of kernel */
	ldr r3, =nested_kernel_entrance_counter
	ldr r2, [r3]
	sub r2, r2, #1
	str r2, [r3]

/* syscalls are reentrant, see kernel_enter macro */
.if (\mode == CPSR_SVC_MODE)
  ldmfd sp!, {r3}
  msr spsr, r3
.endif

.if (\mode == CPSR_SVC_MODE)
	ldmfd sp!, {r0-r3,r9,lr}
.else
  ldmfd sp!, {r0-r3,r9,ip,lr}
.endif

	movs pc, lr /* notice that lr have been corrected from IRQ */
.endm

/* this macro does the main part of the context switch. The last
 * thing to be done is to restore pc from lr and cpsr from spsr.
 *
 * Of course, after this, no register should be altered without
 * being restored. 
 *
 * this macro don't "return", execution continues into switched task
 */
.macro context_switch mode
context_switch_\mode:
  /* r0 points on the static proc table, from where we find the context */
	ldr r0, =tpl_stat_proc_table

	/*
	 * SAVE OLD CONTEXT
	 */

  /* do we need to save the context ? if not, jump to load */
	ldr r2, =tpl_need_switch
	ldrb r2, [r2]
	tst r2, #NEED_SAVE
	beq load_context_\mode
	
	/* get the context block address */
  ldr r2, =old_running_id
  LDR_PROC_ID r2, [r2]

	add r2, r0, r2, LSL #2
  ldr r2, [r2]             /* jump to dynamic descriptor (from static descriptor) */
  ldr r2, [r2]             /* jump to context bloc (from dynamic descriptor) */

	add r2, r2, #(4 * 4)     /* jump over r0-r3 saving zone */
	stmia r2, {r4-r14}^
	sub r2, r2, #(4 * 4)     /* get back to begining of task's saving zone... */

.if (\mode == CPSR_SVC_MODE)
  ldmfd sp!, {r4}          /* as SWI is reentrant, true SPSR is found in the stack */
.else                      /* mode == CPSR_IRQ_MODE */
  mrs r4, spsr
.endif
	str r4, [r2, #(16 * 4)]
	
  /* save ABI's caller-saved registers, those which are saved into
   * kernel_enter macro
   */
.if (\mode == CPSR_SVC_MODE)
	ldmfd sp!, {r4-r7,r9} /* r0-r3 <=> r4-r7 / r9 <=> r9 */
	stmia r2, {r4-r7}
  str r9, [r2, #(9*4)]
.else
  ldmfd sp!, {r4-r7,r9,ip} /* r0-r3 <=> r4-r7 / r9 <=> r9 / ip <=> ip */
  stmia r2, {r4-r7}
  str r9, [r2, #(9*4)]
  str ip, [r2, #(12*4)]
.endif

	ldmfd sp!, {r4}          /* pop task's return address */
	str r4, [r2, #(15 * 4)]  /* and store it into task's saving zone */

load_context_\mode:

  /* We updates kernel reentrance counter while registers are freely
   * usable and as we know we won't enter in kernel again (IRQ locked and
   * no SWI can occur) */
	ldr r3, =nested_kernel_entrance_counter
	ldr r2, [r3]
	sub r2, r2, #1
	str r2, [r3]

	/*
	 * LOAD NEW CONTEXT
	 */
	ldr r2, =tpl_running_id
	LDR_PROC_ID r2, [r2]
	
	/* Get the context block address.
	 *
	 * We use r14 as it will be restored separatly and later, it
	 * is useful for the following ldmia instruction */
	add r14, r0, r2, LSL #2

  ldr r14, [r14]  /* jump to dynamic descriptor (from static descriptor) */
  ldr r14, [r14]  /* jump to context bloc (from dynamic descriptor) */
	
	ldr r0, [r14, #(16 * 4)]
	msr spsr, r0 
	
  ldmia r14, {r0-r14}^

  /* fixes a pipeline problem seen on OKI microcontroller (ARM7TDMI) */
  b pipeline_flush\mode
pipeline_flush\mode:

  ldr r14, [r14, #(15 * 4)] 
  movs pc, r14

/*	ldmia r14, {r0-r15}^ */
.endm

/* this macro clears bit Z (of status register) if context switch is needed */
.macro is_context_switch_needed mode
is_context_switch_needed_\mode:
  ldr r2, =tpl_need_switch
  ldrb r2, [r2]
  cmp r2, #NO_NEED_SWITCH
.endm

.text 
.align 2

.global tpl_init_machine_low_level
tpl_init_machine_low_level:
	stmfd sp!, {r0-r1}

	ldr r0, =nested_kernel_entrance_counter
	mov r1, #0
	str r1, [r0]

	ldmfd sp!, {r0-r1}
	mov pc, lr

/* Main system call handler
 *
 * We pay attention to not alter callee saved registers
 * which are all except r0-r3 (EABI convention). 
 * 
 * We do not use r3 because it is used to give the service number
 * in a system call. After dispatching, r3 can be altered.
 * 
 * This exception to EABI conventions is specific to system call 
 * mechanism.
 */
.global tpl_primary_syscall_handler
tpl_primary_syscall_handler:

	kernel_enter CPSR_SVC_MODE
    
	/* WARNING : r3 should not be altered until here
	 * as it is used to give the service identifier while calling swi
	 *
	 * Note : if service number is invalid we just do nothing and come back
	 */
	cmp r3, #OS_SYSCALL_COUNT
	bhs swi_no_context_switch
	
	/* get the appropriate system call address */
	ldr r1, =tpl_dispatch_table
	ldr r3, [r1, r3, LSL #2]

	/* pop registers values from the stack without altering
	 * the stack (pointer) */
	add sp, sp, #4     /* just jump over SPSR saved value */
	ldmia sp, {r0-r2}
	sub sp, sp, #4

	/* call the service (blx does not exist on ARM7TDMI, so we split it in 
	 * two instructions) */
	mov lr, pc
	bx r3 

  /* we save back returned value (r0-r1) into r0-r1 saved values on the stack */
	add sp, sp, #4
	stmia sp, {r0-r1}
	sub sp, sp, #4

	is_context_switch_needed CPSR_SVC_MODE
	beq swi_no_context_switch

  /* do not switch context if nested kernel entrance */
  ldr r2, =nested_kernel_entrance_counter
  ldr r2, [r2]
  cmp r2, #1
  bhi swi_no_context_switch

	context_switch CPSR_SVC_MODE

swi_no_context_switch:

	kernel_exit_no_switch CPSR_SVC_MODE

/* Main category 2 interrupt handler (IRQ only on this architecture)
 */
.global tpl_primary_irq_handler
tpl_primary_irq_handler:
	kernel_enter CPSR_IRQ_MODE
	
	bl tpl_arm_subarch_irq_handler

	is_context_switch_needed CPSR_IRQ_MODE
	beq irq_no_context_switch
	
	context_switch CPSR_IRQ_MODE
	
irq_no_context_switch:
	
	kernel_exit_no_switch CPSR_IRQ_MODE

